# Flakiness Predicter

This is a step-by-step guideline to use/replicate our classification experiment of flaky tests.   

## Requirements
This is a list of all required python packages to run this part:
- Python >=3.6
- imbalanced_learn >= 0.6.2
- numpy >= 1.18.1
- pandas >= 1.0.1
- scikit_learn >= 0.22.1


## Input Files:
This is a list of input files that are required to accomplish this step:
* `result/processed_data.csv`: 
	This contains our collected features per test generated from `test-feature-collector`. 
* `input_data/original_tests/` :
	This directory contains the body contents of all flaky and non flaky tests. This is used to collect the token/java keywords per test. 

## How to replicate our experiment?
There are three main steps to perform the prediction phase. 
* Hint: the first two steps can be skipped as the generated files from these steps are already in the `result` directory. 

1. Extend the processed_data.csv to contain the tokens and java keywords for each test. This is reuiqred as our main evaluation (Table III in our paper) contains the vocabulary_based_approach (where the classification is only based on the tokens and java keywords collected from each test). The output of this step is already collected and generated as shown in `result/processed_data_with_vocabulary_per_test.csv`. However, it can be re-generated by run:

```console
bash collectTokens.sh
```
This takes the `result/processed_data.csv` and `input_data/original_tests/` as inputs where the output result will override `result/processed_data_with_vocabulary_per_test.csv`


2. Next, the features selection in our classification is based on information gain. To do that, we need to calculate the information gain for each token, java keyword, and FlakeFlagger feature in order to complete the classification. This can be done by run:

```console
bash informationGain.sh
```
This will re-generate the file `result/Information_gain_per_feature.csv`. Please note that this could take several hours to compute the information gain for each features/token (if we consider that there are more than 30k tokens in our provided flaky and non flaky tests).

3. The third step is to build the model based on three approaches which are:
- Evaluation based on FlakeFlagger features only 
- Evaluation based on vocabualry based approach only
- Evaluation based on FlakeFlagger features and vocabualry based approach (merge approach)

running the following :
```console
bash predict.sh
``` 

will build the prediciation models based on the previous three approaches and perform the classification on our dataset. The input of this step are shown in `predict.sh` as follow:
- `result/processed_data_with_vocabulary_per_test.csv`: the extended version of `processed_data.csv` which includes tokens/vocabualry per test.
- `input_data/FlakeFlaggerFeaturesTypes.csv`: the types of flakeflagger features (either static or dynamic).
- `result/Information_gain_per_feature.csv`: the computed information gain for each feature.
- `result/processed_data.csv`: the original collected data from `test-feature-collector`. This is used to map each test to its project for final summary. 

where the output will be under `result/classification_result/` directory which contains three files:
- `prediction_result.csv`: this shows the overall result based on the given selection of arguments.
- `prediction_result_per_test`: list of all False positive, False negative, and True positive, for each result.
- `prediction_result_by_project`: the confusion matrix split by project (similar to Table III in the paper)


** Note: We used `minimum IG = 0.01`, `StratifiedKFold` as cross validation type, `Random Forest (RF)` as a classifier, `5000` as minimum number of trees, `SMOTE` as a balance technique, and `10` as a number of folds. You can change the following arguments to explore the full classification result. The strucutre of these arguments comes as a list (it could be a list of size one argument or more than that). These arguments (shown in `flakeflagger_predicter.py`) are:

	1. Classifier: `RF`, `SVM`, `DT`, `MLP`, `NB`, `KNN` 
	2. Fold types: `StratifiedKFold` and `KFold`
	3. Balance : `SMOTE`, `undersampling` and `none`(to see the result without balancing)
	4. Number of folds: `5` or `10`
	5. Minimum information gain: any value between `0` and `1`
	6. Number of Tree (for RF): `100-5000`
	


## How to apply FlakeFlagger predictor on your data?

### Part 1: Generate processed_data.csv

If you have a dataset of flaky and non-flaky tests and you were able to run *FlakeFlagger* feature collector (Please refer to `test-feature-collector` on how to collect features from a set of java projects), all you need is to generate `processed_data.csv` by running the following command line:

```console
bash generate_data.sh
``` 
Before that, please note that the bash file has three main parts:
- `projects_dir`: it is the head directory which contains all projects where we collect features from.
- `source_of_flaky_tests`: this is a csv file that should contain a list of flaky test names.
- `column_name`: it is the name of the column where flaky tests belong.

For example, if the directory of the java projects is `~/Desktop/projects/`, the csv file of flaky tests is `~/Desktop/flaky_test_list.csv`, and the name of the column in this csv file is `test_name`, then the bash file should be updated to have these three inputs. The `result` folder should contain your generated `processed_data.csv`.

### Part 2: Apply FlakeFlagger 

Running the following command will apply *FlakeFlagger* on your proposed data and the result will be in the folder `extended_FlakeFlagger_result`. 
```console
bash extended-predict.sh
``` 
There are are many possible ways to apply *FlakeFlagger* . To simplify it, we summarize these ways as follow: 

**1. Use Cross-Validation Technique (similar to our paper)**
This is when you want to train *FlakeFlagger* on a **portion** on your data and predict the rest. To apply this, make sure the variables values are in `extended-predict.sh` :
- `training_data="result/your_processed_data.csv"`
- `testing_data="result/your_processed_data.csv"`  This means we use cross validation because there is no external testing dataset. 
- `IG_flag=True`  This means we calculate the information gain of each features based on your dataset
- `kfold=(10)` If you want to train on 90% of your data and predict the rest or `kfold=(5)` if you want to train on 80% of your data and predict the rest.

The result should be in `extended_FlakeFlagger_result/FlakeFlagger-prediction-on-your-dataset/using_cross_validation/`	

**2. Use training-testing datasets**
This is when you have two datasets (two `processed_data.csv` files) and you want to train on one dataset and predict the second dataset. In `extended-predict.sh`, you need to make sure that:
- `training_data="result/your_training_processed_data.csv"`
- `testing_data="result/your_testing_processed_data.csv"`  
- `kfold=(1)` train on all training dataset .
and the rest should be similar to the previous part (1. Use Cross-Validation Technique). 

The result should be in `extended_FlakeFlagger_result/FlakeFlagger-prediction-on-your-dataset/your_data_on_external_testing_dataset/`

**3. Use our pre-trained model to predict your data** 
During our experiment, we saved our baseline model of *FlakeFlagger*. This model was trained on our `processed_data.csv`. To use our pre-trained model, make sure that:
- `training_data="result/processed_data.csv"`
- `testing_data="result/your_processed_data.csv"`  
- `IG_flag=False`  we already calculate the information gain of our dataset.
- `train_model=True`,`fold_type=("StratifiedKFold")` , `balance=("SMOTE")`, `classifier=("RF")`, `treeSize=(100)`, `minIGList=(0.0)`, and `kfold=(1)` 
	
The result should be in `extended_FlakeFlagger_result/FlakeFlagger-prediction-on-your-dataset/our_data_on_external_testing_dataset/`


**Note:** 
We highly recommend to consider applying external testing datasets on FlakeFlagger (**Step 2 and 3**) may not perform well. This is because our dataset does not capture the liklihood of the flakiness causes. However, exploring this will definitely help us to improve the current work.  

**Note:**
Test other configurations of FlakerFlagger such as using a different information gain threshold is recommended. The file  `extended-predict.sh` is designed to let you explore many factors and see their prediction results.  
